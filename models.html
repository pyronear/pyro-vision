

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pyronear.models &mdash; pyronear 0.2.0a0+61d5d52-git documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pyronear.nn" href="nn.html" />
    <link rel="prev" title="pyronear.datasets" href="datasets.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pyronear-logo-dark.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.2.0a0+61d5d52
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="datasets.html">pyronear.datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="datasets.html#openfire">OpenFire</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets.html#wildfire">WildFire</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">pyronear.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#resnet">ResNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#densenet">DenseNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mobilenet-v2">MobileNet v2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#resnext">ResNext</a></li>
<li class="toctree-l2"><a class="reference internal" href="#wide-resnet">Wide ResNet</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">pyronear.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nn.html#pooling-layers">Pooling layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveconcatpool2d">AdaptiveConcatPool2d</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">pyronear.utils</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pyronear</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>pyronear.models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pyronear-models">
<h1>pyronear.models<a class="headerlink" href="#pyronear-models" title="Permalink to this headline">¶</a></h1>
<p>The models subpackage contains definitions of models for addressing different tasks, including: image classification, object detection, and semantic segmentation.</p>
<p>The following models are available:</p>
<div class="contents local topic" id="models">
<p class="topic-title">Models</p>
<ul class="simple">
<li><p><a class="reference internal" href="#resnet" id="id10">ResNet</a></p></li>
<li><p><a class="reference internal" href="#densenet" id="id11">DenseNet</a></p></li>
<li><p><a class="reference internal" href="#mobilenet-v2" id="id12">MobileNet v2</a></p></li>
<li><p><a class="reference internal" href="#resnext" id="id13">ResNext</a></p></li>
<li><p><a class="reference internal" href="#wide-resnet" id="id14">Wide ResNet</a></p></li>
</ul>
</div>
<div class="section" id="resnet">
<h2><a class="toc-backref" href="#id10">ResNet</a><a class="headerlink" href="#resnet" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="pyronear.models.resnet18">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">resnet18</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#resnet18"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.resnet18" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-18 model for image classification from
<a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">“Deep Residual Learning for Image Recognition”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.resnet34">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">resnet34</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#resnet34"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.resnet34" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-34 model for image classification from
<a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">“Deep Residual Learning for Image Recognition”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.resnet50">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">resnet50</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#resnet50"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.resnet50" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-50 model for image classification from
<a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">“Deep Residual Learning for Image Recognition”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.resnet101">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">resnet101</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#resnet101"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.resnet101" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-101 model for image classification from
<a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">“Deep Residual Learning for Image Recognition”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.resnet152">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">resnet152</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#resnet152"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.resnet152" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-152 model for image classification from
<a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">“Deep Residual Learning for Image Recognition”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="densenet">
<h2><a class="toc-backref" href="#id11">DenseNet</a><a class="headerlink" href="#densenet" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="pyronear.models.densenet121">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">densenet121</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/densenet.html#densenet121"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.densenet121" title="Permalink to this definition">¶</a></dt>
<dd><p>Densenet-121 model from
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em>) – If True, returns a model pre-trained on ImageNet</p></li>
<li><p><strong>progress</strong> (<em>bool</em>) – If True, displays a progress bar of the download to stderr</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.densenet.DenseNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.densenet169">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">densenet169</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/densenet.html#densenet169"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.densenet169" title="Permalink to this definition">¶</a></dt>
<dd><p>Densenet-169 model from
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em>) – If True, returns a model pre-trained on ImageNet</p></li>
<li><p><strong>progress</strong> (<em>bool</em>) – If True, displays a progress bar of the download to stderr</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.densenet.DenseNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.densenet161">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">densenet161</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/densenet.html#densenet161"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.densenet161" title="Permalink to this definition">¶</a></dt>
<dd><p>Densenet-161 model from
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em>) – If True, returns a model pre-trained on ImageNet</p></li>
<li><p><strong>progress</strong> (<em>bool</em>) – If True, displays a progress bar of the download to stderr</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.densenet.DenseNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.densenet201">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">densenet201</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/densenet.html#densenet201"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.densenet201" title="Permalink to this definition">¶</a></dt>
<dd><p>Densenet-201 model from
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em>) – If True, returns a model pre-trained on ImageNet</p></li>
<li><p><strong>progress</strong> (<em>bool</em>) – If True, displays a progress bar of the download to stderr</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.densenet.DenseNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="mobilenet-v2">
<h2><a class="toc-backref" href="#id12">MobileNet v2</a><a class="headerlink" href="#mobilenet-v2" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="pyronear.models.mobilenet_v2">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">mobilenet_v2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/mobilenet.html#mobilenet_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.mobilenet_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNetV2 model from
<a class="reference external" href="https://arxiv.org/abs/1801.04381">“MobileNetV2: Inverted Residuals and Linear Bottlenecks”</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em>) – If True, returns a model pre-trained on ImageNet</p></li>
<li><p><strong>progress</strong> (<em>bool</em>) – If True, displays a progress bar of the download to stderr</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.mobilenet.MobileNetV2</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="resnext">
<h2><a class="toc-backref" href="#id13">ResNext</a><a class="headerlink" href="#resnext" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="pyronear.models.resnext50_32x4d">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">resnext50_32x4d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#resnext50_32x4d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.resnext50_32x4d" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNeXt-50 32x4d model from
<a class="reference external" href="https://arxiv.org/pdf/1611.05431.pdf">“Aggregated Residual Transformation for Deep Neural Networks”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.resnext101_32x8d">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">resnext101_32x8d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#resnext101_32x8d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.resnext101_32x8d" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNeXt-101 32x8d model from
<a class="reference external" href="https://arxiv.org/pdf/1611.05431.pdf">“Aggregated Residual Transformation for Deep Neural Networks”</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="wide-resnet">
<h2><a class="toc-backref" href="#id14">Wide ResNet</a><a class="headerlink" href="#wide-resnet" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="pyronear.models.wide_resnet50_2">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">wide_resnet50_2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#wide_resnet50_2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.wide_resnet50_2" title="Permalink to this definition">¶</a></dt>
<dd><p>Wide ResNet-50-2 model from
<a class="reference external" href="https://arxiv.org/pdf/1605.07146.pdf">“Wide Residual Networks”</a></p>
<p>The model is the same as ResNet except for the bottleneck number of channels
which is twice larger in every block. The number of channels in outer 1x1
convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048
channels, and in Wide ResNet-50-2 has 2048-1024-2048.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pyronear.models.wide_resnet101_2">
<code class="sig-prename descclassname">pyronear.models.</code><code class="sig-name descname">wide_resnet101_2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">progress</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imagenet_pretrained</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_classes</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">lin_features</span><span class="o">=</span><span class="default_value">512</span></em>, <em class="sig-param"><span class="n">dropout_prob</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">bn_final</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">concat_pool</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyronear/models/resnet.html#wide_resnet101_2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyronear.models.wide_resnet101_2" title="Permalink to this definition">¶</a></dt>
<dd><p>Wide ResNet-101-2 model from
<a class="reference external" href="https://arxiv.org/pdf/1605.07146.pdf">“Wide Residual Networks”</a></p>
<p>The model is the same as ResNet except for the bottleneck number of channels
which is twice larger in every block. The number of channels in outer 1x1
convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048
channels, and in Wide ResNet-50-2 has 2048-1024-2048.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded (OpenFire training)</p></li>
<li><p><strong>progress</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a progress bar be displayed while downloading pretrained parameters</p></li>
<li><p><strong>imagenet_pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pretrained parameters be loaded on conv layers (ImageNet training)</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of output classes</p></li>
<li><p><strong>lin_features</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>list&lt;int&gt;</em><em>]</em><em>, </em><em>optional</em>) – number of nodes in intermediate layers of model’s head</p></li>
<li><p><strong>dropout_prob</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout probability of head FC layers</p></li>
<li><p><strong>bn_final</strong> (<em>bool</em><em>, </em><em>optional</em>) – should a batch norm be added after the last layer</p></li>
<li><p><strong>concat_pool</strong> (<em>bool</em><em>, </em><em>optional</em>) – should pooling be replaced by <a class="reference internal" href="nn.html#pyronear.nn.AdaptiveConcatPool2d" title="pyronear.nn.AdaptiveConcatPool2d"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pyronear.nn.AdaptiveConcatPool2d</span></code></a></p></li>
<li><p><strong>**kwargs</strong> – optional arguments of <code class="xref py py-mod docutils literal notranslate"><span class="pre">torchvision.models.resnet.ResNet</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="nn.html" class="btn btn-neutral float-right" title="pyronear.nn" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="datasets.html" class="btn btn-neutral float-left" title="pyronear.datasets" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, PyroNear Contributors

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>